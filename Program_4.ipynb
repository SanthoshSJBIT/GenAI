{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqHIejNmmaPrDm7k4Nl4+9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import gensim.downloader as api\n",
        "from transformers import pipeline\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the correct NLTK tokenizer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load pre-trained word vectors\n",
        "print(\"Loading pre-trained word vectors...\")\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # Load GloVe model\n",
        "\n",
        "# Load GPT-2 model for text generation\n",
        "print(\"Loading GPT-2 model...\")\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Function to replace words in the prompt with their most similar words\n",
        "def replace_keyword_in_prompt(prompt, keyword, word_vectors, topn=1):\n",
        "    words = word_tokenize(prompt)  # Tokenize the prompt into words\n",
        "    enriched_words = []\n",
        "\n",
        "    for word in words:\n",
        "        cleaned_word = word.lower().strip(string.punctuation)  # Normalize word\n",
        "        if cleaned_word == keyword.lower():  # Replace only if it matches the keyword\n",
        "            try:\n",
        "                # Retrieve similar word\n",
        "                similar_words = word_vectors.most_similar(cleaned_word, topn=topn)\n",
        "                if similar_words:\n",
        "                    replacement_word = similar_words[0][0]  # Choose the most similar word\n",
        "                    print(f\"Replacing '{word}' â†’ '{replacement_word}'\")\n",
        "                    enriched_words.append(replacement_word)\n",
        "                    continue  # Skip appending the original word\n",
        "            except KeyError:\n",
        "                print(f\"'{keyword}' not found in the vocabulary. Using original word.\")\n",
        "\n",
        "        enriched_words.append(word)  # Keep original if no replacement was made\n",
        "\n",
        "    enriched_prompt = \" \".join(enriched_words)\n",
        "    print(f\"\\nðŸ”¹ Enriched Prompt: {enriched_prompt}\")\n",
        "    return enriched_prompt\n",
        "\n",
        "# Function to generate responses using the Generative AI model\n",
        "def generate_response(prompt, max_length=100):\n",
        "    try:\n",
        "        response = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
        "        return response[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example original prompt\n",
        "original_prompt = \"Who is king.\"\n",
        "print(f\"\\nðŸ”¹ Original Prompt: {original_prompt}\")\n",
        "\n",
        "# Retrieve similar words for key terms in the prompt\n",
        "key_term = \"king\"\n",
        "\n",
        "# Enrich the original prompt\n",
        "enriched_prompt = replace_keyword_in_prompt(original_prompt, key_term, word_vectors)\n",
        "\n",
        "# Generate responses for the original and enriched prompts\n",
        "print(\"\\nGenerating response for the original prompt...\")\n",
        "original_response = generate_response(original_prompt)\n",
        "print(\"\\nOriginal Prompt Response:\")\n",
        "print(original_response)\n",
        "\n",
        "print(\"\\nGenerating response for the enriched prompt...\")\n",
        "enriched_response = generate_response(enriched_prompt)\n",
        "print(\"\\nEnriched Prompt Response:\")\n",
        "print(enriched_response)\n",
        "\n",
        "# Compare the outputs safely\n",
        "if original_response and enriched_response:\n",
        "    print(\"\\nComparison of Responses:\")\n",
        "    print(\"\\nOriginal Prompt Response Length:\", len(original_response))\n",
        "    print(\"Enriched Prompt Response Length:\", len(enriched_response))\n",
        "    print(\"\\nOriginal Prompt Response Detail:\", original_response.count(\".\"))\n",
        "    print(\"Enriched Prompt Response Detail:\", enriched_response.count(\".\"))\n",
        "else:\n",
        "    print(\"\\nOne of the responses could not be generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJxU_wUOlnVo",
        "outputId": "390e2f4a-b97c-440d-d9ef-1386c4376db7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained word vectors...\n",
            "Loading GPT-2 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Original Prompt: Who is king.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacing 'king' â†’ 'prince'\n",
            "\n",
            "ðŸ”¹ Enriched Prompt: Who is prince .\n",
            "\n",
            "Generating response for the original prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Prompt Response:\n",
            "Who is king. How can king be king to a nation that has lost its way? And how can a nation that is trying to make itself known be king to his people?\n",
            "\n",
            "\n",
            "\"This great God of the ancient world used to bless a people who had lost their way and had no way to return home. But when the world grew mad and fell into disorder, then man turned to Heaven as a wayward child. He was promised to come home with me, when the world was ready\n",
            "\n",
            "Generating response for the enriched prompt...\n",
            "\n",
            "Enriched Prompt Response:\n",
            "Who is prince ... what?\" \"Don't count it...\" \"Yes. The king... was. The prince, when, after an hour, there were three persons, who were of the same rank as their king, viz. the King's and Prince's, and their rank was of the same rank as the Emperor...\" But, now, if that were so, it could hardly be said that the emperor was the most worthy of having done the best of\n",
            "\n",
            "Comparison of Responses:\n",
            "\n",
            "Original Prompt Response Length: 425\n",
            "Enriched Prompt Response Length: 367\n",
            "\n",
            "Original Prompt Response Detail: 3\n",
            "Enriched Prompt Response Detail: 15\n"
          ]
        }
      ]
    }
  ]
}